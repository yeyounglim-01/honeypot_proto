from fastapi import APIRouter, UploadFile, File, HTTPException, BackgroundTasks, Form, Depends, Request
from app.auth import get_current_user
from app.routers.auth import verify_csrf_token
from app.services.blob_service import upload_to_blob, save_processed_json
from app.services.document_service import extract_text_from_url, extract_text_from_docx
from app.services.search_service import add_document_to_index, get_document_count, get_all_documents
import uuid
import traceback
from app.state import task_manager
from app.services.openai_service import analyze_text_for_search
from app.services.search_service import index_processed_chunks
import json

router = APIRouter()

"""
@router.post("/upload")
async def upload_document(file: UploadFile = File(...)):
    try:
        # 1. íŒŒì¼ ë°ì´í„° ì½ê¸°
        file_data = await file.read()
        
        # 2. íŒŒì¼ í™•ì¥ì í™•ì¸
        file_ext = file.filename.lower().split('.')[-1] if '.' in file.filename else ''
        
        # 3. txt íŒŒì¼ì€ ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ, PDF/ì´ë¯¸ì§€ëŠ” Document Intelligence ì‚¬ìš©
        if file_ext == 'txt':
            # txt íŒŒì¼ì€ ì§ì ‘ ë””ì½”ë”©
            try:
                extracted_text = file_data.decode('utf-8')
            except UnicodeDecodeError:
                extracted_text = file_data.decode('cp949', errors='ignore')
        else:
            # PDF, ì´ë¯¸ì§€ ë“±ì€ Blob ì—…ë¡œë“œ í›„ Document Intelligence ì‚¬ìš©
            try:
                print(f"ğŸ“¤ Blob ì—…ë¡œë“œ ì‹œë„: {file.filename}")
                blob_url = upload_to_blob(file.filename, file_data)
                print(f"âœ… Blob ì—…ë¡œë“œ ì™„ë£Œ: {blob_url}")
                
                print(f"ğŸ” Document Intelligenceë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘...")
                extracted_text = extract_text_from_url(blob_url)
                print(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ ({len(extracted_text)} ê¸€ì)")
            except Exception as doc_error:
                print(f"âš ï¸  Document Intelligence ì‹¤íŒ¨: {doc_error}")
                # Document Intelligence ì‹¤íŒ¨ ì‹œ íŒŒì¼ëª…ê³¼ ê¸°ë³¸ ë©”ì‹œì§€ë¡œ í´ë°±
                extracted_text = f"[íŒŒì¼ëª…: {file.filename}]\n[ì£¼ì˜: ìë™ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨. Document Intelligence ì„¤ì • í•„ìš”]\n\níŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
        
        # 4. AI Searchì— ì¸ë±ì‹± (ì‹¤íŒ¨í•´ë„ í…ìŠ¤íŠ¸ëŠ” ë°˜í™˜)
        doc_id = str(uuid.uuid4())
        try:
            add_document_to_index(doc_id, extracted_text, file.filename)
            print(f"âœ… AI Search ì¸ë±ì‹± ì™„ë£Œ")
        except Exception as index_error:
            print(f"âš ï¸  AI Search ì¸ë±ì‹± ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {index_error}")
        
        return {
            "message": "ë¬¸ì„œ ì—…ë¡œë“œ ì™„ë£Œ",
            "file_name": file.filename,
            "doc_id": doc_id,
            "extracted_text": extracted_text
        }
    except Exception as e:
        print(f"âŒ Upload error: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Upload error: {str(e)}")
"""

#ì°½í›ˆ ì½”ë“œ ì¶”ê°€

async def process_file_background(task_id: str, file_name: str, file_data: bytes, file_ext: str, index_name: str = None):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë  ì‹¤ì œ íŒŒì´í”„ë¼ì¸ ë¡œì§
    1. Blob ì—…ë¡œë“œ (Raw)
    2. í…ìŠ¤íŠ¸ ì¶”ì¶œ
    3. LLM ì „ì²˜ë¦¬ (JSON ìƒì„±)
    4. Blob ì—…ë¡œë“œ (Processed JSON)
    5. Azure Search ì¸ë±ì‹±

    Args:
        index_name: RAG ì¸ë±ìŠ¤ ì´ë¦„ (ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ì¸ë±ìŠ¤ ì‚¬ìš©)
    """
    try:
        print(f"[Background] Processing task {task_id} for file {file_name}...")
        task_manager.update_task(task_id, status="processing", progress=10, message=f"Uploading raw file: {file_name}")
        
        # 1. Blob ì—…ë¡œë“œ (Raw)
        # ì¤‘ìš”: íŒŒì¼ëª…ì— í•œê¸€/íŠ¹ìˆ˜ë¬¸ì/ê³µë°±ì´ ìˆìœ¼ë©´ Document Intelligenceê°€ URL ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í•¨.
        # ë”°ë¼ì„œ Blob ì €ì¥ ì‹œì—ëŠ” ì•ˆì „í•œ ì˜ë¬¸ ì´ë¦„(Task ID)ì„ ì‚¬ìš©í•˜ê³ , ì›ë³¸ íŒŒì¼ëª…ì€ ë©”íƒ€ë°ì´í„°ë¡œë§Œ ê´€ë¦¬í•¨.
        safe_file_name = f"{task_id}.{file_ext}" if file_ext else task_id

        try:
            # upload_to_blobì€ ì´ë¯¸ SAS Tokenì´ í¬í•¨ëœ URLì„ ë°˜í™˜í•¨
            blob_url_with_sas = upload_to_blob(safe_file_name, file_data, index_name=index_name)
            print(f"[Background] Blob upload success: {blob_url_with_sas}")
            
        except Exception as e:
            print(f"[Background] Blob upload failed: {e}")
            raise e

        task_manager.update_task(task_id, progress=30, message="Extracting text...")
        
        # 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ
        extracted_text = ""
        if file_ext in ['txt', 'py', 'js', 'java', 'c', 'cpp', 'h', 'cs', 'ts', 'tsx', 'html', 'css', 'json', 'md']:
            # í…ìŠ¤íŠ¸/ì½”ë“œ íŒŒì¼ì€ ì§ì ‘ ë””ì½”ë”©
            try:
                extracted_text = file_data.decode('utf-8')
            except UnicodeDecodeError:
                extracted_text = file_data.decode('cp949', errors='ignore')
        elif file_ext == 'docx':
            # DOCX ë¡œì»¬ ì¶”ì¶œ (ë¹ ë¥´ê³  ë¬´ë£Œ, URL ì—ëŸ¬ ì—†ìŒ)
            print("[Background] File is DOCX. Attempting local extraction...")
            try:
                extracted_text = extract_text_from_docx(file_data)
                print(f"[Background] DOCX extraction success. Length: {len(extracted_text)}")
            except Exception as e:
                print(f"[Background] DOCX extraction failed: {e}")
                task_manager.update_task(task_id, status="failed", message=f"DOCX extraction failed: {str(e)}")
                return
        else:
            # PDF, ì´ë¯¸ì§€ ë“±ì€ Document Intelligence ì‚¬ìš© (SAS Token í¬í•¨ URL ì‚¬ìš©)
            try:
                extracted_text = extract_text_from_url(blob_url_with_sas)
            except Exception as e:
                task_manager.update_task(task_id, status="failed", message=f"Text extraction failed: {str(e)}")
                return

        if not extracted_text:
            task_manager.update_task(task_id, status="failed", message="No text extracted from file.")
            return
            
        task_manager.update_task(task_id, progress=50, message="Analyzing with AI (Preprocessing)...")
        print("[Background] Starting LLM analysis...")

        # 3. LLM ì „ì²˜ë¦¬
        # íŒŒì¼ ìœ í˜• êµ¬ë¶„ (code vs doc)
        file_type = "code" if file_ext in ['py', 'js', 'java', 'cpp', 'ts', 'tsx', 'cs'] else "doc"
        
        # print(f"extracted_text : {extracted_text}")
        chunks = analyze_text_for_search(extracted_text, file_name, file_type=file_type)
        print(f"[Background] LLM analysis returned {len(chunks) if chunks else 0} chunks.")
        
        if not chunks:
            task_manager.update_task(task_id, status="failed", message="AI preprocessing failed (No chunks generated).")
            return

        task_manager.update_task(task_id, progress=70, message="Saving processed data...")

        # 4. Processed JSON ì €ì¥ (Blob)
        # JSON íŒŒì¼ëª…ë„ ì•ˆì „í•˜ê²Œ Task ID ê¸°ë°˜ìœ¼ë¡œ ì €ì¥
        processed_file_name = f"{task_id}_processed.json"
        try:
            json_str = json.dumps(chunks, ensure_ascii=False, indent=2)
            save_processed_json(processed_file_name, json_str, index_name=index_name)
        except Exception as e:
            print(f"âš ï¸ Failed to save processed json: {e}")
            # ì €ì¥ì€ ì‹¤íŒ¨í•´ë„ ì§„í–‰

        task_manager.update_task(task_id, progress=80, message="Indexing to Search...")

        # 5. Azure Search ì¸ë±ì‹±
        print(f"[Background] Starting indexing for {len(chunks)} chunks to index '{index_name or 'default'}'...")
        try:
            indexed_count = index_processed_chunks(chunks, index_name=index_name)
            print(f"[Background] Indexing complete. Count: {indexed_count}")
        except Exception as e:
            print(f"[Background] Indexing failed: {e}")
            raise e
        
        if indexed_count > 0:
            task_manager.update_task(task_id, status="completed", progress=100, message="Upload & Indexing Complete!")
        else:
            task_manager.update_task(task_id, status="completed_with_warning", progress=100, message="Finished, but no documents indexed.")

    except Exception as e:
        print(f"âŒ Background task failed: {e}")
        traceback.print_exc()
        task_manager.update_task(task_id, status="failed", message=f"Internal Server Error: {str(e)}")


@router.post("")
async def upload_document(
    request: Request,
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    index_name: str = Form(None),
    user: dict = Depends(get_current_user)
):
    # CSRF ê²€ì¦ ì¶”ê°€
    csrf_token = request.headers.get("X-CSRF-Token")
    if not csrf_token:
        raise HTTPException(
            status_code=403,
            detail="CSRF Tokenì´ í•„ìš”í•©ë‹ˆë‹¤."
        )
    verify_csrf_token(csrf_token, user['email'])
    """
    íŒŒì¼ ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸ (ë¹„ë™ê¸° ì²˜ë¦¬)
    íŒŒì¼ì„ ë°›ìë§ˆì task_idë¥¼ ë¦¬í„´í•˜ê³ , ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ ì‹œì‘.

    Args:
        file: ì—…ë¡œë“œí•  íŒŒì¼
        index_name: RAG ì¸ë±ìŠ¤ ì´ë¦„ (ì„ íƒ ì‚¬í•­, ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ì¸ë±ìŠ¤)
    """
    try:
        # 1. íŒŒì¼ ë°ì´í„° ì½ê¸° (ë©”ëª¨ë¦¬)
        file_data = await file.read()
        file_name = file.filename
        file_ext = file_name.lower().split('.')[-1] if '.' in file_name else ''

        # 2. Task ìƒì„±
        task_id = str(uuid.uuid4())
        task_manager.create_task(task_id)

        # 3. ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ë“±ë¡
        print(f"ğŸ“‹ Upload request: file={file_name}, index={index_name or 'default'}")
        background_tasks.add_task(process_file_background, task_id, file_name, file_data, file_ext, index_name)

        return {
            "message": "Upload started",
            "task_id": task_id,
            "file_name": file_name,
            "index_name": index_name or "default"
        }
        
    except Exception as e:
        print(f"âŒ Upload request failed: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/status/{task_id}")
async def get_task_status(task_id: str):
    """ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    return task



@router.get("/stats")
async def get_stats(index_name: str = "documents-index"):
    """ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ - ìµœê·¼ ì—…ë¡œë“œ ê°¯ìˆ˜, ì¸ë±ìŠ¤ ë¬¸ì„œ ê°¯ìˆ˜"""
    try:
        doc_count = get_document_count(index_name)
        print(f"ğŸ“Š ì‹œìŠ¤í…œ í†µê³„: {doc_count}ê°œ ë¬¸ì„œ ì¸ë±ì‹±ë¨")
        
        return {
            "total_documents": doc_count,
            "recent_uploads": doc_count,  # AI Searchì— ì¸ë±ì‹±ëœ ëª¨ë“  ë¬¸ì„œ
            "status": "âœ… Active",
            "index_name": index_name
        }
    except Exception as e:
        print(f"âŒ Stats error: {e}")
        return {
            "total_documents": 0,
            "recent_uploads": 0,
            "status": "âš ï¸ Error",
            "index_name": index_name
        }

@router.get("/documents")
async def list_documents():
    """AI Search ì¸ë±ìŠ¤ì— ì €ì¥ëœ ëª¨ë“  ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ - ì‹¤ì œ content í¬í•¨"""
    try:
        from app.services.search_service import get_search_client
        
        search_client = get_search_client()
        results = search_client.search(search_text="*", include_total_count=True, top=100)
        
        docs = []
        for result in results:
            docs.append({
                "id": result.get("id", ""),
                "file_name": result.get("file_name", "Unknown"),
                "content": result.get("content", ""),  # ì‹¤ì œ content í¬í•¨!
                "content_length": len(result.get("content", ""))
            })
        
        print(f"ğŸ“‹ API ì‘ë‹µ: {len(docs)}ê°œ ë¬¸ì„œ (ì‹¤ì œ content í¬í•¨)")
        
        return {
            "count": len(docs),
            "documents": docs
        }
    except Exception as e:
        print(f"âŒ Documents list error: {e}")
        traceback.print_exc()
        return {
            "count": 0,
            "documents": []
        }

@router.get("/indexes")
async def list_indexes():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  RAG ì¸ë±ìŠ¤ ëª©ë¡ ì¡°íšŒ"""
    try:
        from app.services.search_service import get_search_index_client
        
        index_client = get_search_index_client()
        indexes = index_client.list_indexes()
        
        index_list = []
        for index in indexes:
            index_list.append({
                "name": index.name,
                "fields_count": len(index.fields) if index.fields else 0
            })
        
        print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì¸ë±ìŠ¤: {len(index_list)}ê°œ")
        for idx in index_list:
            print(f"   - {idx['name']}")
        
        return {
            "count": len(index_list),
            "indexes": index_list
        }
    except Exception as e:
        print(f"âŒ Index list error: {e}")
        traceback.print_exc()
        return {
            "count": 0,
            "indexes": []
        }
